{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nhanbaoho/logistic-regression-accuracy-97?scriptVersionId=98212468\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"---\n# Contents\n1. Importing libraries\n2. Reading data\n3. Analysing and Visualising data\n4. Preprocessing data \n5. Spliting and Scaling data\n6. Building the model\n7. Evaluating model performance\n8. Plotting performance curves","metadata":{}},{"cell_type":"markdown","source":"---\n# 1. Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.145371Z","iopub.execute_input":"2022-05-29T11:35:22.145819Z","iopub.status.idle":"2022-05-29T11:35:22.150766Z","shell.execute_reply.started":"2022-05-29T11:35:22.145783Z","shell.execute_reply":"2022-05-29T11:35:22.149941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 2. Read data\n### Read data into a dataframe named \"df\"","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.232379Z","iopub.execute_input":"2022-05-29T11:35:22.233057Z","iopub.status.idle":"2022-05-29T11:35:22.288477Z","shell.execute_reply.started":"2022-05-29T11:35:22.232994Z","shell.execute_reply":"2022-05-29T11:35:22.287123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.transpose()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.315182Z","iopub.execute_input":"2022-05-29T11:35:22.316475Z","iopub.status.idle":"2022-05-29T11:35:22.37828Z","shell.execute_reply.started":"2022-05-29T11:35:22.316372Z","shell.execute_reply":"2022-05-29T11:35:22.377235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can drop \"id\" and \"Unnamed: 32\" columns as they are not features","metadata":{}},{"cell_type":"code","source":"df = df.drop([\"id\", \"Unnamed: 32\"], axis = 1)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.387848Z","iopub.execute_input":"2022-05-29T11:35:22.388347Z","iopub.status.idle":"2022-05-29T11:35:22.431815Z","shell.execute_reply.started":"2022-05-29T11:35:22.388311Z","shell.execute_reply":"2022-05-29T11:35:22.430782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 3. Analysing and Visualising data","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Explore information about dataframe: index dtype, columns, non-null values, memory usage","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.458296Z","iopub.execute_input":"2022-05-29T11:35:22.459355Z","iopub.status.idle":"2022-05-29T11:35:22.477186Z","shell.execute_reply.started":"2022-05-29T11:35:22.459298Z","shell.execute_reply":"2022-05-29T11:35:22.475302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Explore  descriptive statistics about dataframe.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.52526Z","iopub.execute_input":"2022-05-29T11:35:22.526532Z","iopub.status.idle":"2022-05-29T11:35:22.62584Z","shell.execute_reply.started":"2022-05-29T11:35:22.526468Z","shell.execute_reply":"2022-05-29T11:35:22.624789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().transpose()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.628421Z","iopub.execute_input":"2022-05-29T11:35:22.628927Z","iopub.status.idle":"2022-05-29T11:35:22.72312Z","shell.execute_reply.started":"2022-05-29T11:35:22.62888Z","shell.execute_reply":"2022-05-29T11:35:22.722417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Explore correlation between features.","metadata":{}},{"cell_type":"code","source":"# matrix of correlation\ndf.corr()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.724578Z","iopub.execute_input":"2022-05-29T11:35:22.725038Z","iopub.status.idle":"2022-05-29T11:35:22.778824Z","shell.execute_reply.started":"2022-05-29T11:35:22.724993Z","shell.execute_reply":"2022-05-29T11:35:22.777847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4. Create a heatmap that displays the correlation between all the columns\n\nPlot heatmap with lower triangle","metadata":{}},{"cell_type":"code","source":"# figure size\nplt.figure(figsize=(20,12))\n# correlation matrix\ncorr = df.corr()\n# upper triangle is marked\nmarked_matrix = np.triu(corr)\n# plot heatmap\nsns.heatmap(data = corr, cmap='viridis', annot=True, mask = marked_matrix)  # ","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.780435Z","iopub.execute_input":"2022-05-29T11:35:22.780986Z","iopub.status.idle":"2022-05-29T11:35:25.216129Z","shell.execute_reply.started":"2022-05-29T11:35:22.78095Z","shell.execute_reply":"2022-05-29T11:35:25.215082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 4. Preprocessing data \n* There are many features that are highly correlated. We aims to remove them in the next step. A comparison below suggests that removal of correlation of those greater than 0.85 gives us the best combination of accuracy and running effectiveness.","metadata":{}},{"cell_type":"markdown","source":"## 4.1. Feature sellection\n\n\n### Features that are highly correlated (correlation abs > 0.85) are about to be removed.","metadata":{}},{"cell_type":"code","source":"# correlation matrix\ncorr = df.corr()\ncorr_abs = corr.abs()\n# select upper triangle of correlation matrix\nupper_triangle = corr_abs.where(np.triu(np.ones(corr_abs.shape), k=1).astype(np.bool))\n\n# columns with high correlation to be dropped\n# dropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.75)]  # this give accuracy 95%\n# dropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.8)]     # this give accuracy 95%\ndropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.85)]  # accuracy 97%\n# dropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.9)]     # 97%\n\n# drop columns from dataframe\ndf = df.drop(dropped_columns, axis = 1)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.218482Z","iopub.execute_input":"2022-05-29T11:35:25.219194Z","iopub.status.idle":"2022-05-29T11:35:25.267664Z","shell.execute_reply.started":"2022-05-29T11:35:25.219145Z","shell.execute_reply":"2022-05-29T11:35:25.266661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore features that were dropped","metadata":{}},{"cell_type":"code","source":"dropped_columns","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.269246Z","iopub.execute_input":"2022-05-29T11:35:25.269679Z","iopub.status.idle":"2022-05-29T11:35:25.277192Z","shell.execute_reply.started":"2022-05-29T11:35:25.269646Z","shell.execute_reply":"2022-05-29T11:35:25.275921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are 13 featured removed as shown below.","metadata":{}},{"cell_type":"code","source":"len(dropped_columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.279777Z","iopub.execute_input":"2022-05-29T11:35:25.281232Z","iopub.status.idle":"2022-05-29T11:35:25.292694Z","shell.execute_reply.started":"2022-05-29T11:35:25.281173Z","shell.execute_reply":"2022-05-29T11:35:25.291693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Display the relationships between selected features in a pair plot.","metadata":{}},{"cell_type":"code","source":"# figure size\nplt.figure(figsize=(15,15))\n# pairplot\nsns.pairplot(df, hue='diagnosis')","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.29413Z","iopub.execute_input":"2022-05-29T11:35:25.294998Z","iopub.status.idle":"2022-05-29T11:37:24.338889Z","shell.execute_reply.started":"2022-05-29T11:35:25.294955Z","shell.execute_reply":"2022-05-29T11:37:24.333452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. Features X and target y\n\n### We first drop the column \"diagnosis\" to obtain X = features. The column y = \"diagnosis\" is target.","metadata":{}},{"cell_type":"code","source":"# Features\nX = df.drop(\"diagnosis\", axis = 1)\n\n# Target\ny = df[\"diagnosis\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.34068Z","iopub.execute_input":"2022-05-29T11:37:24.341153Z","iopub.status.idle":"2022-05-29T11:37:24.348644Z","shell.execute_reply.started":"2022-05-29T11:37:24.341113Z","shell.execute_reply":"2022-05-29T11:37:24.347719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore target values","metadata":{}},{"cell_type":"code","source":"y.unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.349953Z","iopub.execute_input":"2022-05-29T11:37:24.350503Z","iopub.status.idle":"2022-05-29T11:37:24.365841Z","shell.execute_reply.started":"2022-05-29T11:37:24.350463Z","shell.execute_reply":"2022-05-29T11:37:24.365079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count target values\n* The binary target values suggests a model of Logictic Regression.","metadata":{}},{"cell_type":"code","source":"y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.367183Z","iopub.execute_input":"2022-05-29T11:37:24.367637Z","iopub.status.idle":"2022-05-29T11:37:24.381972Z","shell.execute_reply.started":"2022-05-29T11:37:24.367607Z","shell.execute_reply":"2022-05-29T11:37:24.381029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot total count of target values","metadata":{}},{"cell_type":"code","source":"# figure size\nplt.figure(figsize=(8, 5))\nsns.countplot(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.383526Z","iopub.execute_input":"2022-05-29T11:37:24.38385Z","iopub.status.idle":"2022-05-29T11:37:24.587526Z","shell.execute_reply.started":"2022-05-29T11:37:24.383821Z","shell.execute_reply":"2022-05-29T11:37:24.586499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot a piechart of target","metadata":{}},{"cell_type":"code","source":"# declaring data\ndata = y.value_counts()\nkeys = y.unique()\n  \n# define Seaborn color palette to use\npalette_color = sns.color_palette('bright')\n  \n# plotting data on chart\nplt.pie(data, labels=keys, colors=palette_color, autopct='%.0f%%')\n  \n# displaying chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.590514Z","iopub.execute_input":"2022-05-29T11:37:24.590897Z","iopub.status.idle":"2022-05-29T11:37:24.693258Z","shell.execute_reply.started":"2022-05-29T11:37:24.590865Z","shell.execute_reply":"2022-05-29T11:37:24.692068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 5. Spliting and Scaling data","metadata":{}},{"cell_type":"markdown","source":"## 5.1. Import libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.695424Z","iopub.execute_input":"2022-05-29T11:37:24.695944Z","iopub.status.idle":"2022-05-29T11:37:24.701683Z","shell.execute_reply.started":"2022-05-29T11:37:24.695896Z","shell.execute_reply":"2022-05-29T11:37:24.700587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2. Spliting for training and testing. We use 30% of data for testing","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# We use 30% of data for testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.703715Z","iopub.execute_input":"2022-05-29T11:37:24.704234Z","iopub.status.idle":"2022-05-29T11:37:24.719629Z","shell.execute_reply.started":"2022-05-29T11:37:24.704185Z","shell.execute_reply":"2022-05-29T11:37:24.717923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 Standardising and Trainging\n#### Create a StandardScaler object and normalize the X train and test set feature data. This will standardize our data to new data that has normal distribution N(0, 1). Then fit to the training data.\n","metadata":{}},{"cell_type":"code","source":"# Create an object of StandardScaler\nscaler = StandardScaler()\n\n# We only fit to the training data, not test data.\nscaled_X_train = scaler.fit_transform(X_train)\n\n# We transform but not fit the test data.\nscaled_X_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.721362Z","iopub.execute_input":"2022-05-29T11:37:24.722364Z","iopub.status.idle":"2022-05-29T11:37:24.741206Z","shell.execute_reply.started":"2022-05-29T11:37:24.722304Z","shell.execute_reply":"2022-05-29T11:37:24.739707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 6. Building the model: Logistic Regression Model\n* One option for this dataset of binary target values is Logictic Regression. ","metadata":{}},{"cell_type":"markdown","source":"### 6.1. Import the model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.743259Z","iopub.execute_input":"2022-05-29T11:37:24.743803Z","iopub.status.idle":"2022-05-29T11:37:24.749057Z","shell.execute_reply.started":"2022-05-29T11:37:24.743747Z","shell.execute_reply":"2022-05-29T11:37:24.748002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### 6.2. Create an instance of LogisticRegression model","metadata":{}},{"cell_type":"code","source":"log_model = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.751175Z","iopub.execute_input":"2022-05-29T11:37:24.752022Z","iopub.status.idle":"2022-05-29T11:37:24.76368Z","shell.execute_reply.started":"2022-05-29T11:37:24.751955Z","shell.execute_reply":"2022-05-29T11:37:24.762423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3. Training the model on the data","metadata":{}},{"cell_type":"code","source":"log_model.fit(scaled_X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.76593Z","iopub.execute_input":"2022-05-29T11:37:24.76678Z","iopub.status.idle":"2022-05-29T11:37:24.792468Z","shell.execute_reply.started":"2022-05-29T11:37:24.766726Z","shell.execute_reply":"2022-05-29T11:37:24.791781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.4. Predict on test data","metadata":{}},{"cell_type":"code","source":"y_pred = log_model.predict(scaled_X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.793822Z","iopub.execute_input":"2022-05-29T11:37:24.794345Z","iopub.status.idle":"2022-05-29T11:37:24.801161Z","shell.execute_reply.started":"2022-05-29T11:37:24.79431Z","shell.execute_reply":"2022-05-29T11:37:24.800419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 7. Evaluating model performance","metadata":{}},{"cell_type":"markdown","source":"## 7.1. Import","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.802219Z","iopub.execute_input":"2022-05-29T11:37:24.802635Z","iopub.status.idle":"2022-05-29T11:37:24.813089Z","shell.execute_reply.started":"2022-05-29T11:37:24.802607Z","shell.execute_reply":"2022-05-29T11:37:24.812333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2. Measuring Model Performance\n* The model accuracy is 97%","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"score = accuracy_score(y_test,y_pred, normalize=True)\nscore","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.81454Z","iopub.execute_input":"2022-05-29T11:37:24.81518Z","iopub.status.idle":"2022-05-29T11:37:24.828933Z","shell.execute_reply.started":"2022-05-29T11:37:24.815133Z","shell.execute_reply":"2022-05-29T11:37:24.827916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.3. Confusion Matrix","metadata":{}},{"cell_type":"code","source":"conf_matrix = confusion_matrix(y_test, y_pred)\nconf_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.830294Z","iopub.execute_input":"2022-05-29T11:37:24.830675Z","iopub.status.idle":"2022-05-29T11:37:24.84291Z","shell.execute_reply.started":"2022-05-29T11:37:24.830645Z","shell.execute_reply":"2022-05-29T11:37:24.841819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization of confusion_matrix","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(log_model,scaled_X_test,y_test)\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 10);","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.844615Z","iopub.execute_input":"2022-05-29T11:37:24.844958Z","iopub.status.idle":"2022-05-29T11:37:25.104897Z","shell.execute_reply.started":"2022-05-29T11:37:24.844927Z","shell.execute_reply":"2022-05-29T11:37:25.103774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling plot to frequency. This gives us better insight.","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(log_model,scaled_X_test,y_test,normalize='true')","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.106914Z","iopub.execute_input":"2022-05-29T11:37:25.107475Z","iopub.status.idle":"2022-05-29T11:37:25.368878Z","shell.execute_reply.started":"2022-05-29T11:37:25.107437Z","shell.execute_reply":"2022-05-29T11:37:25.367603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.4. Classification report","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.370297Z","iopub.execute_input":"2022-05-29T11:37:25.370674Z","iopub.status.idle":"2022-05-29T11:37:25.389875Z","shell.execute_reply.started":"2022-05-29T11:37:25.370643Z","shell.execute_reply":"2022-05-29T11:37:25.388539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 8. Plotting performance curves","metadata":{}},{"cell_type":"markdown","source":"## Insight\n* https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n* https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","metadata":{}},{"cell_type":"markdown","source":"## 8.1. Import","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import plot_precision_recall_curve,plot_roc_curve","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.391209Z","iopub.execute_input":"2022-05-29T11:37:25.392416Z","iopub.status.idle":"2022-05-29T11:37:25.39706Z","shell.execute_reply.started":"2022-05-29T11:37:25.392371Z","shell.execute_reply":"2022-05-29T11:37:25.395947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.2. Plot the Precision-Recall curve\n* The precision-recall curve below shows both high recall and high precision.","metadata":{}},{"cell_type":"code","source":"plot_precision_recall_curve(log_model,scaled_X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.398428Z","iopub.execute_input":"2022-05-29T11:37:25.399228Z","iopub.status.idle":"2022-05-29T11:37:25.639972Z","shell.execute_reply.started":"2022-05-29T11:37:25.399192Z","shell.execute_reply":"2022-05-29T11:37:25.639068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.3 Plot Receiver operating characteristic (ROC) curve\n* The ROC curve below shows the area under the curve approaches almost 1.","metadata":{}},{"cell_type":"code","source":"plot_roc_curve(log_model,scaled_X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.641277Z","iopub.execute_input":"2022-05-29T11:37:25.641727Z","iopub.status.idle":"2022-05-29T11:37:25.883147Z","shell.execute_reply.started":"2022-05-29T11:37:25.641696Z","shell.execute_reply":"2022-05-29T11:37:25.882274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"---\n# Thanks for your interest and your feedback!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}