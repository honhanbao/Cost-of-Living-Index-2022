{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nhanbaoho/logistic-regression-accuracy-97?scriptVersionId=98728361\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **<center>Classification Model for Breast Cancer Wisconsin**","metadata":{}},{"cell_type":"markdown","source":"# **Dataset**\n\nhttps://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\n\n\"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\nn the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\nAlso can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)\nb) texture (standard deviation of gray-scale values)\nc) perimeter\nd) area\ne) smoothness (local variation in radius lengths)\nf) compactness (perimeter^2 / area - 1.0)\ng) concavity (severity of concave portions of the contour)\nh) concave points (number of concave portions of the contour)\ni) symmetry\nj) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant\"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# **Goal**\nWe will build a Classification Model to predict predict whether a person has presence of breast cancer based on physical features of cell nucleus of that person.\n\n\n    ","metadata":{}},{"cell_type":"markdown","source":"---\n# **Contents**\n1. [Exploring Data Analysis (EDA)](#1)\n2. [Feature Selection](#2)\n3. [Choosing Model](#3)\n4. [Traing Data](#4)\n5. [Evaluating model performance](#5)\n","metadata":{}},{"cell_type":"markdown","source":"---\n# **1. Exploring Data Analysis**","metadata":{}},{"cell_type":"markdown","source":"## **1.a. Import packages for exploring data**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-06-19T01:28:16.653476Z","iopub.execute_input":"2022-06-19T01:28:16.65394Z","iopub.status.idle":"2022-06-19T01:28:16.658881Z","shell.execute_reply.started":"2022-06-19T01:28:16.653906Z","shell.execute_reply":"2022-06-19T01:28:16.657824Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## **1.b. Read data into a dataframe named \"df\"**","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-19T01:29:31.626787Z","iopub.execute_input":"2022-06-19T01:29:31.627223Z","iopub.status.idle":"2022-06-19T01:29:31.677455Z","shell.execute_reply.started":"2022-06-19T01:29:31.627187Z","shell.execute_reply":"2022-06-19T01:29:31.676493Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0      842302         M        17.99         10.38          122.80     1001.0   \n1      842517         M        20.57         17.77          132.90     1326.0   \n2    84300903         M        19.69         21.25          130.00     1203.0   \n3    84348301         M        11.42         20.38           77.58      386.1   \n4    84358402         M        20.29         14.34          135.10     1297.0   \n..        ...       ...          ...           ...             ...        ...   \n564    926424         M        21.56         22.39          142.00     1479.0   \n565    926682         M        20.13         28.25          131.20     1261.0   \n566    926954         M        16.60         28.08          108.30      858.1   \n567    927241         M        20.60         29.33          140.10     1265.0   \n568     92751         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0    ...          17.33           184.60      2019.0           0.16220   \n1    ...          23.41           158.80      1956.0           0.12380   \n2    ...          25.53           152.50      1709.0           0.14440   \n3    ...          26.50            98.87       567.7           0.20980   \n4    ...          16.67           152.20      1575.0           0.13740   \n..   ...            ...              ...         ...               ...   \n564  ...          26.40           166.10      2027.0           0.14100   \n565  ...          38.25           155.00      1731.0           0.11660   \n566  ...          34.12           126.70      1124.0           0.11390   \n567  ...          39.42           184.60      1821.0           0.16500   \n568  ...          30.37            59.16       268.6           0.08996   \n\n     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0              0.66560           0.7119                0.2654          0.4601   \n1              0.18660           0.2416                0.1860          0.2750   \n2              0.42450           0.4504                0.2430          0.3613   \n3              0.86630           0.6869                0.2575          0.6638   \n4              0.20500           0.4000                0.1625          0.2364   \n..                 ...              ...                   ...             ...   \n564            0.21130           0.4107                0.2216          0.2060   \n565            0.19220           0.3215                0.1628          0.2572   \n566            0.30940           0.3403                0.1418          0.2218   \n567            0.86810           0.9387                0.2650          0.4087   \n568            0.06444           0.0000                0.0000          0.2871   \n\n     fractal_dimension_worst  Unnamed: 32  \n0                    0.11890          NaN  \n1                    0.08902          NaN  \n2                    0.08758          NaN  \n3                    0.17300          NaN  \n4                    0.07678          NaN  \n..                       ...          ...  \n564                  0.07115          NaN  \n565                  0.06637          NaN  \n566                  0.07820          NaN  \n567                  0.12400          NaN  \n568                  0.07039          NaN  \n\n[569 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## **1.c. Clean data**","metadata":{}},{"cell_type":"markdown","source":"We can drop \"id\" and \"Unnamed: 32\" columns as they are not features","metadata":{}},{"cell_type":"code","source":"df = df.drop([\"id\", \"Unnamed: 32\"], axis = 1)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-19T01:32:27.29934Z","iopub.execute_input":"2022-06-19T01:32:27.300109Z","iopub.status.idle":"2022-06-19T01:32:27.346341Z","shell.execute_reply.started":"2022-06-19T01:32:27.300067Z","shell.execute_reply":"2022-06-19T01:32:27.345499Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0           M        17.99         10.38          122.80     1001.0   \n1           M        20.57         17.77          132.90     1326.0   \n2           M        19.69         21.25          130.00     1203.0   \n3           M        11.42         20.38           77.58      386.1   \n4           M        20.29         14.34          135.10     1297.0   \n..        ...          ...           ...             ...        ...   \n564         M        21.56         22.39          142.00     1479.0   \n565         M        20.13         28.25          131.20     1261.0   \n566         M        16.60         28.08          108.30      858.1   \n567         M        20.60         29.33          140.10     1265.0   \n568         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0           0.2419  ...        25.380          17.33           184.60   \n1           0.1812  ...        24.990          23.41           158.80   \n2           0.2069  ...        23.570          25.53           152.50   \n3           0.2597  ...        14.910          26.50            98.87   \n4           0.1809  ...        22.540          16.67           152.20   \n..             ...  ...           ...            ...              ...   \n564         0.1726  ...        25.450          26.40           166.10   \n565         0.1752  ...        23.690          38.25           155.00   \n566         0.1590  ...        18.980          34.12           126.70   \n567         0.2397  ...        25.740          39.42           184.60   \n568         0.1587  ...         9.456          30.37            59.16   \n\n     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0        2019.0           0.16220            0.66560           0.7119   \n1        1956.0           0.12380            0.18660           0.2416   \n2        1709.0           0.14440            0.42450           0.4504   \n3         567.7           0.20980            0.86630           0.6869   \n4        1575.0           0.13740            0.20500           0.4000   \n..          ...               ...                ...              ...   \n564      2027.0           0.14100            0.21130           0.4107   \n565      1731.0           0.11660            0.19220           0.3215   \n566      1124.0           0.11390            0.30940           0.3403   \n567      1821.0           0.16500            0.86810           0.9387   \n568       268.6           0.08996            0.06444           0.0000   \n\n     concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                  0.2654          0.4601                  0.11890  \n1                  0.1860          0.2750                  0.08902  \n2                  0.2430          0.3613                  0.08758  \n3                  0.2575          0.6638                  0.17300  \n4                  0.1625          0.2364                  0.07678  \n..                    ...             ...                      ...  \n564                0.2216          0.2060                  0.07115  \n565                0.1628          0.2572                  0.06637  \n566                0.1418          0.2218                  0.07820  \n567                0.2650          0.4087                  0.12400  \n568                0.0000          0.2871                  0.07039  \n\n[569 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.380</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.990</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.570</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.910</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.540</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>...</td>\n      <td>25.450</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>...</td>\n      <td>23.690</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>...</td>\n      <td>18.980</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>...</td>\n      <td>9.456</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n# 3. Analysing and Visualising data","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Explore information about dataframe: index dtype, columns, non-null values, memory usage","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.458296Z","iopub.execute_input":"2022-05-29T11:35:22.459355Z","iopub.status.idle":"2022-05-29T11:35:22.477186Z","shell.execute_reply.started":"2022-05-29T11:35:22.459298Z","shell.execute_reply":"2022-05-29T11:35:22.475302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Explore  descriptive statistics about dataframe.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.52526Z","iopub.execute_input":"2022-05-29T11:35:22.526532Z","iopub.status.idle":"2022-05-29T11:35:22.62584Z","shell.execute_reply.started":"2022-05-29T11:35:22.526468Z","shell.execute_reply":"2022-05-29T11:35:22.624789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().transpose()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.628421Z","iopub.execute_input":"2022-05-29T11:35:22.628927Z","iopub.status.idle":"2022-05-29T11:35:22.72312Z","shell.execute_reply.started":"2022-05-29T11:35:22.62888Z","shell.execute_reply":"2022-05-29T11:35:22.722417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3. Explore correlation between features.","metadata":{}},{"cell_type":"code","source":"# matrix of correlation\ndf.corr()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.724578Z","iopub.execute_input":"2022-05-29T11:35:22.725038Z","iopub.status.idle":"2022-05-29T11:35:22.778824Z","shell.execute_reply.started":"2022-05-29T11:35:22.724993Z","shell.execute_reply":"2022-05-29T11:35:22.777847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4. Create a heatmap that displays the correlation between all the columns\n\nPlot heatmap with lower triangle","metadata":{}},{"cell_type":"code","source":"# figure size\nplt.figure(figsize=(20,12))\n# correlation matrix\ncorr = df.corr()\n# upper triangle is marked\nmarked_matrix = np.triu(corr)\n# plot heatmap\nsns.heatmap(data = corr, cmap='viridis', annot=True, mask = marked_matrix)  # ","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:22.780435Z","iopub.execute_input":"2022-05-29T11:35:22.780986Z","iopub.status.idle":"2022-05-29T11:35:25.216129Z","shell.execute_reply.started":"2022-05-29T11:35:22.78095Z","shell.execute_reply":"2022-05-29T11:35:25.215082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 4. Preprocessing data \n* There are many features that are highly correlated. We aims to remove them in the next step. A comparison below suggests that removal of correlation of those greater than 0.85 gives us the best combination of accuracy and running effectiveness.","metadata":{}},{"cell_type":"markdown","source":"## 4.1. Feature sellection\n\n\n### Features that are highly correlated (correlation abs > 0.85) are about to be removed.","metadata":{}},{"cell_type":"code","source":"# correlation matrix\ncorr = df.corr()\ncorr_abs = corr.abs()\n# select upper triangle of correlation matrix\nupper_triangle = corr_abs.where(np.triu(np.ones(corr_abs.shape), k=1).astype(np.bool))\n\n# columns with high correlation to be dropped\n# dropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.75)]  # this give accuracy 95%\n# dropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.8)]     # this give accuracy 95%\ndropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.85)]  # accuracy 97%\n# dropped_columns = [col for col in upper_triangle.columns if any(upper_triangle[col] > 0.9)]     # 97%\n\n# drop columns from dataframe\ndf = df.drop(dropped_columns, axis = 1)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.218482Z","iopub.execute_input":"2022-05-29T11:35:25.219194Z","iopub.status.idle":"2022-05-29T11:35:25.267664Z","shell.execute_reply.started":"2022-05-29T11:35:25.219145Z","shell.execute_reply":"2022-05-29T11:35:25.266661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore features that were dropped","metadata":{}},{"cell_type":"code","source":"dropped_columns","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.269246Z","iopub.execute_input":"2022-05-29T11:35:25.269679Z","iopub.status.idle":"2022-05-29T11:35:25.277192Z","shell.execute_reply.started":"2022-05-29T11:35:25.269646Z","shell.execute_reply":"2022-05-29T11:35:25.275921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are 13 featured removed as shown below.","metadata":{}},{"cell_type":"code","source":"len(dropped_columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.279777Z","iopub.execute_input":"2022-05-29T11:35:25.281232Z","iopub.status.idle":"2022-05-29T11:35:25.292694Z","shell.execute_reply.started":"2022-05-29T11:35:25.281173Z","shell.execute_reply":"2022-05-29T11:35:25.291693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Display the relationships between selected features in a pair plot.","metadata":{}},{"cell_type":"code","source":"# figure size\nplt.figure(figsize=(15,15))\n# pairplot\nsns.pairplot(df, hue='diagnosis')","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:35:25.29413Z","iopub.execute_input":"2022-05-29T11:35:25.294998Z","iopub.status.idle":"2022-05-29T11:37:24.338889Z","shell.execute_reply.started":"2022-05-29T11:35:25.294955Z","shell.execute_reply":"2022-05-29T11:37:24.333452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. Features X and target y\n\n### We first drop the column \"diagnosis\" to obtain X = features. The column y = \"diagnosis\" is target.","metadata":{}},{"cell_type":"code","source":"# Features\nX = df.drop(\"diagnosis\", axis = 1)\n\n# Target\ny = df[\"diagnosis\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.34068Z","iopub.execute_input":"2022-05-29T11:37:24.341153Z","iopub.status.idle":"2022-05-29T11:37:24.348644Z","shell.execute_reply.started":"2022-05-29T11:37:24.341113Z","shell.execute_reply":"2022-05-29T11:37:24.347719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore target values","metadata":{}},{"cell_type":"code","source":"y.unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.349953Z","iopub.execute_input":"2022-05-29T11:37:24.350503Z","iopub.status.idle":"2022-05-29T11:37:24.365841Z","shell.execute_reply.started":"2022-05-29T11:37:24.350463Z","shell.execute_reply":"2022-05-29T11:37:24.365079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count target values\n* The binary target values suggests a model of Logictic Regression.","metadata":{}},{"cell_type":"code","source":"y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.367183Z","iopub.execute_input":"2022-05-29T11:37:24.367637Z","iopub.status.idle":"2022-05-29T11:37:24.381972Z","shell.execute_reply.started":"2022-05-29T11:37:24.367607Z","shell.execute_reply":"2022-05-29T11:37:24.381029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot total count of target values","metadata":{}},{"cell_type":"code","source":"# figure size\nplt.figure(figsize=(8, 5))\nsns.countplot(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.383526Z","iopub.execute_input":"2022-05-29T11:37:24.38385Z","iopub.status.idle":"2022-05-29T11:37:24.587526Z","shell.execute_reply.started":"2022-05-29T11:37:24.383821Z","shell.execute_reply":"2022-05-29T11:37:24.586499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plot a piechart of target","metadata":{}},{"cell_type":"code","source":"# declaring data\ndata = y.value_counts()\nkeys = y.unique()\n  \n# define Seaborn color palette to use\npalette_color = sns.color_palette('bright')\n  \n# plotting data on chart\nplt.pie(data, labels=keys, colors=palette_color, autopct='%.0f%%')\n  \n# displaying chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.590514Z","iopub.execute_input":"2022-05-29T11:37:24.590897Z","iopub.status.idle":"2022-05-29T11:37:24.693258Z","shell.execute_reply.started":"2022-05-29T11:37:24.590865Z","shell.execute_reply":"2022-05-29T11:37:24.692068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 5. Spliting and Scaling data","metadata":{}},{"cell_type":"markdown","source":"## 5.1. Import libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.695424Z","iopub.execute_input":"2022-05-29T11:37:24.695944Z","iopub.status.idle":"2022-05-29T11:37:24.701683Z","shell.execute_reply.started":"2022-05-29T11:37:24.695896Z","shell.execute_reply":"2022-05-29T11:37:24.700587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2. Spliting for training and testing. We use 30% of data for testing","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# We use 30% of data for testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.703715Z","iopub.execute_input":"2022-05-29T11:37:24.704234Z","iopub.status.idle":"2022-05-29T11:37:24.719629Z","shell.execute_reply.started":"2022-05-29T11:37:24.704185Z","shell.execute_reply":"2022-05-29T11:37:24.717923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 Standardising and Trainging\n#### Create a StandardScaler object and normalize the X train and test set feature data. This will standardize our data to new data that has normal distribution N(0, 1). Then fit to the training data.\n","metadata":{}},{"cell_type":"code","source":"# Create an object of StandardScaler\nscaler = StandardScaler()\n\n# We only fit to the training data, not test data.\nscaled_X_train = scaler.fit_transform(X_train)\n\n# We transform but not fit the test data.\nscaled_X_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.721362Z","iopub.execute_input":"2022-05-29T11:37:24.722364Z","iopub.status.idle":"2022-05-29T11:37:24.741206Z","shell.execute_reply.started":"2022-05-29T11:37:24.722304Z","shell.execute_reply":"2022-05-29T11:37:24.739707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 6. Building the model: Logistic Regression Model\n* One option for this dataset of binary target values is Logictic Regression. ","metadata":{}},{"cell_type":"markdown","source":"### 6.1. Import the model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.743259Z","iopub.execute_input":"2022-05-29T11:37:24.743803Z","iopub.status.idle":"2022-05-29T11:37:24.749057Z","shell.execute_reply.started":"2022-05-29T11:37:24.743747Z","shell.execute_reply":"2022-05-29T11:37:24.748002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### 6.2. Create an instance of LogisticRegression model","metadata":{}},{"cell_type":"code","source":"log_model = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.751175Z","iopub.execute_input":"2022-05-29T11:37:24.752022Z","iopub.status.idle":"2022-05-29T11:37:24.76368Z","shell.execute_reply.started":"2022-05-29T11:37:24.751955Z","shell.execute_reply":"2022-05-29T11:37:24.762423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3. Training the model on the data","metadata":{}},{"cell_type":"code","source":"log_model.fit(scaled_X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.76593Z","iopub.execute_input":"2022-05-29T11:37:24.76678Z","iopub.status.idle":"2022-05-29T11:37:24.792468Z","shell.execute_reply.started":"2022-05-29T11:37:24.766726Z","shell.execute_reply":"2022-05-29T11:37:24.791781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.4. Predict on test data","metadata":{}},{"cell_type":"code","source":"y_pred = log_model.predict(scaled_X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.793822Z","iopub.execute_input":"2022-05-29T11:37:24.794345Z","iopub.status.idle":"2022-05-29T11:37:24.801161Z","shell.execute_reply.started":"2022-05-29T11:37:24.79431Z","shell.execute_reply":"2022-05-29T11:37:24.800419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 7. Evaluating model performance","metadata":{}},{"cell_type":"markdown","source":"## 7.1. Import","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.802219Z","iopub.execute_input":"2022-05-29T11:37:24.802635Z","iopub.status.idle":"2022-05-29T11:37:24.813089Z","shell.execute_reply.started":"2022-05-29T11:37:24.802607Z","shell.execute_reply":"2022-05-29T11:37:24.812333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2. Measuring Model Performance\n* The model accuracy is 97%","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"score = accuracy_score(y_test,y_pred, normalize=True)\nscore","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.81454Z","iopub.execute_input":"2022-05-29T11:37:24.81518Z","iopub.status.idle":"2022-05-29T11:37:24.828933Z","shell.execute_reply.started":"2022-05-29T11:37:24.815133Z","shell.execute_reply":"2022-05-29T11:37:24.827916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7.3. Confusion Matrix","metadata":{}},{"cell_type":"code","source":"conf_matrix = confusion_matrix(y_test, y_pred)\nconf_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.830294Z","iopub.execute_input":"2022-05-29T11:37:24.830675Z","iopub.status.idle":"2022-05-29T11:37:24.84291Z","shell.execute_reply.started":"2022-05-29T11:37:24.830645Z","shell.execute_reply":"2022-05-29T11:37:24.841819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualization of confusion_matrix","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(log_model,scaled_X_test,y_test)\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 10);","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:24.844615Z","iopub.execute_input":"2022-05-29T11:37:24.844958Z","iopub.status.idle":"2022-05-29T11:37:25.104897Z","shell.execute_reply.started":"2022-05-29T11:37:24.844927Z","shell.execute_reply":"2022-05-29T11:37:25.103774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling plot to frequency. This gives us better insight.","metadata":{}},{"cell_type":"code","source":"plot_confusion_matrix(log_model,scaled_X_test,y_test,normalize='true')","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.106914Z","iopub.execute_input":"2022-05-29T11:37:25.107475Z","iopub.status.idle":"2022-05-29T11:37:25.368878Z","shell.execute_reply.started":"2022-05-29T11:37:25.107437Z","shell.execute_reply":"2022-05-29T11:37:25.367603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.4. Classification report","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.370297Z","iopub.execute_input":"2022-05-29T11:37:25.370674Z","iopub.status.idle":"2022-05-29T11:37:25.389875Z","shell.execute_reply.started":"2022-05-29T11:37:25.370643Z","shell.execute_reply":"2022-05-29T11:37:25.388539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 8. Plotting performance curves","metadata":{}},{"cell_type":"markdown","source":"## Insight\n* https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n* https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","metadata":{}},{"cell_type":"markdown","source":"## 8.1. Import","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import plot_precision_recall_curve,plot_roc_curve","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.391209Z","iopub.execute_input":"2022-05-29T11:37:25.392416Z","iopub.status.idle":"2022-05-29T11:37:25.39706Z","shell.execute_reply.started":"2022-05-29T11:37:25.392371Z","shell.execute_reply":"2022-05-29T11:37:25.395947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.2. Plot the Precision-Recall curve\n* The precision-recall curve below shows both high recall and high precision.","metadata":{}},{"cell_type":"code","source":"plot_precision_recall_curve(log_model,scaled_X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.398428Z","iopub.execute_input":"2022-05-29T11:37:25.399228Z","iopub.status.idle":"2022-05-29T11:37:25.639972Z","shell.execute_reply.started":"2022-05-29T11:37:25.399192Z","shell.execute_reply":"2022-05-29T11:37:25.639068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.3 Plot Receiver operating characteristic (ROC) curve\n* The ROC curve below shows the area under the curve approaches almost 1.","metadata":{}},{"cell_type":"code","source":"plot_roc_curve(log_model,scaled_X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T11:37:25.641277Z","iopub.execute_input":"2022-05-29T11:37:25.641727Z","iopub.status.idle":"2022-05-29T11:37:25.883147Z","shell.execute_reply.started":"2022-05-29T11:37:25.641696Z","shell.execute_reply":"2022-05-29T11:37:25.882274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"---\n# Thanks for your interest and your feedback!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}